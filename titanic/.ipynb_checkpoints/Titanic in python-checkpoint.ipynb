{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Titanic kaggle competition\n",
    "\n",
    "Notes on predicting survivals on titanic with the data from corresponding kaggle competition.\n",
    "\n",
    "First, we read the training data and have a look at it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex  Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male   22      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
      "2                             Heikkinen, Miss. Laina  female   26      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35      1   \n",
      "4                           Allen, Mr. William Henry    male   35      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "titanic=pd.read_csv('train.csv')\n",
    "print(titanic.head())\n",
    "print(titanic.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column `age` has missing values. We don't want to omit this data so we fill it with the median of existing ages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic[\"Age\"] = titanic[\"Age\"].fillna(titanic[\"Age\"].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll ignore `Ticket`, `Cabin` and `Name` columns. Ticket number and name don't tell much whether a person is going to survive and there is to many missing values in `Cabin` column\n",
    "\n",
    "To deal with `Sex` we'll replace \"male\" with 0 and \"female\" with 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male' 'female']\n"
     ]
    }
   ],
   "source": [
    "#check for unique values in the column\n",
    "print(titanic[\"Sex\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic.loc[titanic[\"Sex\"] == \"male\", \"Sex\"]=0\n",
    "titanic.loc[titanic[\"Sex\"] == \"female\", \"Sex\"]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to the `Embarked` column. We'll assign to the missing values the most popular value 'S' and replace all values with numbers starting from 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S' 'C' 'Q' nan]\n"
     ]
    }
   ],
   "source": [
    "print(titanic[\"Embarked\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S' 'C' 'Q']\n"
     ]
    }
   ],
   "source": [
    "titanic[\"Embarked\"]=titanic[\"Embarked\"].fillna('S')\n",
    "print(titanic[\"Embarked\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic.loc[titanic[\"Embarked\"] == 'S', \"Embarked\"] = 0\n",
    "titanic.loc[titanic[\"Embarked\"] == 'C', \"Embarked\"] = 1\n",
    "titanic.loc[titanic[\"Embarked\"] == 'Q', \"Embarked\"] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict with linear regression using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the linear regression class\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Sklearn also has a helper that makes it easy to do cross validation\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "# The columns we'll use to predict the target\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "# Initialize our algorithm class\n",
    "alg = LinearRegression()\n",
    "# Generate cross validation folds for the titanic dataset.  It return the row indices corresponding to train and test.\n",
    "# We set random_state to ensure we get the same splits every time we run this.\n",
    "kf = KFold(titanic.shape[0], n_folds=3, random_state=1)\n",
    "\n",
    "predictions = []\n",
    "for train, test in kf:\n",
    "    # The predictors we're using the train the algorithm.  Note how we only take the rows in the train folds.\n",
    "    train_predictors = (titanic[predictors].iloc[train,:])\n",
    "    # The target we're using to train the algorithm.\n",
    "    train_target = titanic[\"Survived\"].iloc[train]\n",
    "    # Training the algorithm using the predictors and target.\n",
    "    alg.fit(train_predictors, train_target)\n",
    "    # We can now make predictions on the test fold\n",
    "    test_predictions = alg.predict(titanic[predictors].iloc[test,:])\n",
    "    predictions.append(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78338945005611671"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# The predictions are in three separate numpy arrays.  Concatenate them into one.  \n",
    "# We concatenate them on axis 0, as they only have one axis.\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# Map predictions to outcomes (only possible outcomes are 1 and 0)\n",
    "predictions[predictions > .5] = 1\n",
    "predictions[predictions <=.5] = 0\n",
    "accuracy = (predictions==titanic[\"Survived\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to the logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.787878787879\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize our algorithm\n",
    "alg = LogisticRegression(random_state=1)\n",
    "# Compute the accuracy score for all the cross validation folds.  (much simpler than what we did before!)\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n",
    "# Take the mean of the scores (because we have one for each fold)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to the processing of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_test=pd.read_csv('test.csv')\n",
    "titanic_test[\"Age\"] = titanic_test[\"Age\"].fillna(titanic[\"Age\"].median())\n",
    "titanic_test.loc[titanic_test[\"Sex\"] == \"male\", \"Sex\"]=0\n",
    "titanic_test.loc[titanic_test[\"Sex\"] == \"female\", \"Sex\"]=1\n",
    "titanic_test[\"Embarked\"]=titanic_test[\"Embarked\"].fillna('S')\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == 'S', \"Embarked\"] = 0\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == 'C', \"Embarked\"] = 1\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == 'Q', \"Embarked\"] = 2\n",
    "titanic_test[\"Fare\"] = titanic_test[\"Fare\"].fillna(titanic[\"Fare\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alg.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "\n",
    "predictions = alg.predict(titanic_test[predictors])\n",
    "\n",
    "# Create a new dataframe with only the columns Kaggle wants from the dataset.\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": titanic_test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "\n",
    "submission.to_csv(\"kaggle.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll do the prediction using random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.800224466891\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=10, min_samples_split=2, min_samples_leaf=1)\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's tweak some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.819304152637\n"
     ]
    }
   ],
   "source": [
    "alg = RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=4, min_samples_leaf=2)\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generating a familysize column\n",
    "titanic[\"FamilySize\"] = titanic[\"SibSp\"] + titanic[\"Parch\"]\n",
    "\n",
    "# The .apply method generates a new series\n",
    "titanic[\"NameLength\"] = titanic[\"Name\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract titles from the name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr          517\n",
      "Miss        182\n",
      "Mrs         125\n",
      "Master       40\n",
      "Dr            7\n",
      "Rev           6\n",
      "Mlle          2\n",
      "Major         2\n",
      "Col           2\n",
      "Mme           1\n",
      "Don           1\n",
      "Jonkheer      1\n",
      "Ms            1\n",
      "Capt          1\n",
      "Sir           1\n",
      "Countess      1\n",
      "Lady          1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# A function to get the title from a name.\n",
    "def get_title(name):\n",
    "    # Use a regular expression to search for a title.  Titles always consist of capital and lowercase letters, and end with a period.\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "# Get all the titles and print how often each one occurs.\n",
    "titles = titanic[\"Name\"].apply(get_title)\n",
    "print(pd.value_counts(titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     517\n",
      "2     183\n",
      "3     125\n",
      "4      40\n",
      "5       7\n",
      "6       6\n",
      "7       5\n",
      "10      3\n",
      "8       3\n",
      "9       2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Map each title to an integer.  Some titles are very rare, and are compressed into the same codes as other titles.\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2}\n",
    "for k,v in title_mapping.items():\n",
    "    titles[titles == k] = v\n",
    "\n",
    "# Verify that we converted everything.\n",
    "print(pd.value_counts(titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add in the title column.\n",
    "titanic[\"Title\"] = titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1      800\n",
      " 14       8\n",
      " 149      7\n",
      " 63       6\n",
      " 50       6\n",
      " 59       6\n",
      " 17       5\n",
      " 384      4\n",
      " 27       4\n",
      " 25       4\n",
      " 162      4\n",
      " 8        4\n",
      " 84       4\n",
      " 340      4\n",
      " 43       3\n",
      " 269      3\n",
      " 58       3\n",
      " 633      2\n",
      " 167      2\n",
      " 280      2\n",
      " 510      2\n",
      " 90       2\n",
      " 83       1\n",
      " 625      1\n",
      " 376      1\n",
      " 449      1\n",
      " 498      1\n",
      " 588      1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "# A dictionary mapping family name to id\n",
    "family_id_mapping = {}\n",
    "\n",
    "# A function to get the id given a row\n",
    "def get_family_id(row):\n",
    "    # Find the last name by splitting on a comma\n",
    "    last_name = row[\"Name\"].split(\",\")[0]\n",
    "    # Create the family id\n",
    "    family_id = \"{0}{1}\".format(last_name, row[\"FamilySize\"])\n",
    "    # Look up the id in the mapping\n",
    "    if family_id not in family_id_mapping:\n",
    "        if len(family_id_mapping) == 0:\n",
    "            current_id = 1\n",
    "        else:\n",
    "            # Get the maximum id from the mapping and add one to it if we don't have an id\n",
    "            current_id = (max(family_id_mapping.items(), key=operator.itemgetter(1))[1] + 1)\n",
    "        family_id_mapping[family_id] = current_id\n",
    "    return family_id_mapping[family_id]\n",
    "\n",
    "# Get the family ids with the apply method\n",
    "family_ids = titanic.apply(get_family_id, axis=1)\n",
    "\n",
    "# There are a lot of family ids, so we'll compress all of the families under 3 members into one code.\n",
    "family_ids[titanic[\"FamilySize\"] < 3] = -1\n",
    "\n",
    "# Print the count of each unique id.\n",
    "print(pd.value_counts(family_ids))\n",
    "\n",
    "titanic[\"FamilyId\"] = family_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do selection of best values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEoCAYAAAB4oxv+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCn7oAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6b6b8bb630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.811447811448\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"FamilyId\"]\n",
    "\n",
    "# Perform feature selection\n",
    "selector = SelectKBest(f_classif, k=5)\n",
    "selector.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "\n",
    "# Get the raw p-values for each feature, and transform from p-values into scores\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "\n",
    "# Plot the scores.  See how \"Pclass\", \"Sex\", \"Title\", and \"Fare\" are the best?\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "plt.bar(range(len(predictors)), scores)\n",
    "plt.xticks(range(len(predictors)), predictors, rotation='vertical')\n",
    "plt.show()\n",
    "\n",
    "# Pick only the four best features.\n",
    "predictors = [\"Pclass\", \"Sex\", \"Fare\", \"Title\"]\n",
    "\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=8, min_samples_leaf=4)\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.819304152637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/egor/anaconda3/lib/python3.4/site-packages/IPython/kernel/__main__.py:37: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "\n",
    "# The algorithms we want to ensemble.\n",
    "# We're using the more linear predictors for the logistic regression, and everything with the gradient boosting classifier.\n",
    "algorithms = [\n",
    "    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"FamilyId\"]],\n",
    "    [LogisticRegression(random_state=1), [\"Pclass\", \"Sex\", \"Fare\", \"FamilySize\", \"Title\", \"Age\", \"Embarked\"]]\n",
    "]\n",
    "\n",
    "# Initialize the cross validation folds\n",
    "kf = KFold(titanic.shape[0], n_folds=3, random_state=1)\n",
    "\n",
    "predictions = []\n",
    "for train, test in kf:\n",
    "    train_target = titanic[\"Survived\"].iloc[train]\n",
    "    full_test_predictions = []\n",
    "    # Make predictions for each algorithm on each fold\n",
    "    for alg, predictors in algorithms:\n",
    "        # Fit the algorithm on the training data.\n",
    "        alg.fit(titanic[predictors].iloc[train,:], train_target)\n",
    "        # Select and predict on the test fold.  \n",
    "        # The .astype(float) is necessary to convert the dataframe to all floats and avoid an sklearn error.\n",
    "        test_predictions = alg.predict_proba(titanic[predictors].iloc[test,:].astype(float))[:,1]\n",
    "        full_test_predictions.append(test_predictions)\n",
    "    # Use a simple ensembling scheme -- just average the predictions to get the final classification.\n",
    "    test_predictions = (full_test_predictions[0] + full_test_predictions[1]) / 2\n",
    "    # Any value over .5 is assumed to be a 1 prediction, and below .5 is a 0 prediction.\n",
    "    test_predictions[test_predictions <= .5] = 0\n",
    "    test_predictions[test_predictions > .5] = 1\n",
    "    predictions.append(test_predictions)\n",
    "\n",
    "# Put all the predictions together into one array.\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# Compute accuracy by comparing to the training data.\n",
    "accuracy = sum(predictions[predictions == titanic[\"Survived\"]]) / len(predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     240\n",
      "2      79\n",
      "3      72\n",
      "4      21\n",
      "7       2\n",
      "6       2\n",
      "10      1\n",
      "5       1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#process test data\n",
    "\n",
    "# First, we'll add titles to the test set.\n",
    "titles = titanic_test[\"Name\"].apply(get_title)\n",
    "# We're adding the Dona title to the mapping, because it's in the test set, but not the training set\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2, \"Dona\": 10}\n",
    "for k,v in title_mapping.items():\n",
    "    titles[titles == k] = v\n",
    "titanic_test[\"Title\"] = titles\n",
    "# Check the counts of each unique title.\n",
    "print(pd.value_counts(titanic_test[\"Title\"]))\n",
    "\n",
    "# Now, we add the family size column.\n",
    "titanic_test[\"FamilySize\"] = titanic_test[\"SibSp\"] + titanic_test[\"Parch\"]\n",
    "\n",
    "# Now we can add family ids.\n",
    "family_ids = titanic_test.apply(get_family_id, axis=1)\n",
    "family_ids[titanic_test[\"FamilySize\"] < 3] = -1\n",
    "titanic_test[\"FamilyId\"] = family_ids\n",
    "\n",
    "titanic_test[\"NameLength\"] = titanic_test[\"Name\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predicting on test data\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"FamilyId\"]\n",
    "\n",
    "algorithms = [\n",
    "    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), predictors],\n",
    "    [LogisticRegression(random_state=1), [\"Pclass\", \"Sex\", \"Fare\", \"FamilySize\", \"Title\", \"Age\", \"Embarked\"]]\n",
    "]\n",
    "\n",
    "full_predictions = []\n",
    "for alg, predictors in algorithms:\n",
    "    # Fit the algorithm using the full training data.\n",
    "    alg.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "    # Predict using the test dataset.  We have to convert all the columns to floats to avoid an error.\n",
    "    predictions = alg.predict_proba(titanic_test[predictors].astype(float))[:,1]\n",
    "    full_predictions.append(predictions)\n",
    "\n",
    "# The gradient boosting classifier generates better predictions, so we weight it higher.\n",
    "predictions = (full_predictions[0] * 3 + full_predictions[1]) / 4\n",
    "predictions[predictions > .5] = 1\n",
    "predictions[predictions <=.5] = 0\n",
    "predictions=predictions.astype(int)\n",
    "# Create a new dataframe with only the columns Kaggle wants from the dataset.\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": titanic_test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "\n",
    "submission.to_csv(\"kaggle_gbc+logreg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This submission gives 0.79904 precision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
