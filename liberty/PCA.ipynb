{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn import preprocessing\n",
    "\n",
    "train=pd.read_csv('train.csv', index_col=0)\n",
    "test=pd.read_csv('test.csv', index_col=0)\n",
    "# label encode the categorical variables\n",
    "for i in range(train.shape[1]):\n",
    "    if train.iloc[:,i].dtype=='O':\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(train.iloc[:,i]) + list(test.iloc[:,i-1]))\n",
    "        train.iloc[:,i] = lbl.transform(train.iloc[:,i])\n",
    "        test.iloc[:,i-1] = lbl.transform(test.iloc[:,i-1])\n",
    "\n",
    "predictors=train.columns.values.tolist()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Gini(y_true, y_pred):\n",
    "    # check and get number of samples\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    n_samples = y_true.shape[0]\n",
    "    \n",
    "    # sort true values on prediction column \n",
    "    # (from largest to smallest)\n",
    "    arr = np.array([y_true, y_pred]).transpose()\n",
    "    true_order = arr[arr[:,0].argsort()][::-1,0]\n",
    "    pred_order = arr[arr[:,1].argsort()][::-1,0]\n",
    "    \n",
    "    # get Lorenz curves\n",
    "    L_true = np.cumsum(true_order) / np.sum(true_order)\n",
    "    L_pred = np.cumsum(pred_order) / np.sum(pred_order)\n",
    "    L_ones = np.linspace(1/n_samples, 1, n_samples)\n",
    "    \n",
    "    # get Gini coefficients (area between curves)\n",
    "    G_true = np.sum(L_ones - L_true)\n",
    "    G_pred = np.sum(L_ones - L_pred)\n",
    "    \n",
    "    # normalize to true Gini coefficient\n",
    "    return G_pred/G_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.64052477,  0.70485142,  0.7564948 ,  0.79856712,  0.83778807,\n",
       "        0.86766186,  0.89369798,  0.91860659,  0.94218318,  0.95708022,\n",
       "        0.96476384,  0.97198989,  0.9779114 ,  0.98241782,  0.98656103,\n",
       "        0.98997094])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=16)\n",
    "pca.fit(train[predictors])\n",
    "np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_pca=pd.DataFrame(pca.transform(train[predictors]))\n",
    "train_pca['Hazard']=np.array(train.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>Hazard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.011624</td>\n",
       "      <td>2.197549</td>\n",
       "      <td>11.270368</td>\n",
       "      <td>-0.560723</td>\n",
       "      <td>-3.857200</td>\n",
       "      <td>4.611379</td>\n",
       "      <td>-5.389250</td>\n",
       "      <td>-0.374177</td>\n",
       "      <td>0.689210</td>\n",
       "      <td>0.140596</td>\n",
       "      <td>0.122384</td>\n",
       "      <td>1.126142</td>\n",
       "      <td>1.305294</td>\n",
       "      <td>-0.038265</td>\n",
       "      <td>1.539655</td>\n",
       "      <td>-1.044174</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-20.554059</td>\n",
       "      <td>-4.985823</td>\n",
       "      <td>3.950644</td>\n",
       "      <td>-4.083574</td>\n",
       "      <td>11.507768</td>\n",
       "      <td>5.285352</td>\n",
       "      <td>-7.959067</td>\n",
       "      <td>4.183133</td>\n",
       "      <td>-4.442317</td>\n",
       "      <td>-4.939957</td>\n",
       "      <td>0.019306</td>\n",
       "      <td>5.375269</td>\n",
       "      <td>1.012978</td>\n",
       "      <td>0.344369</td>\n",
       "      <td>0.571722</td>\n",
       "      <td>1.589332</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-13.485705</td>\n",
       "      <td>-0.326685</td>\n",
       "      <td>-5.549856</td>\n",
       "      <td>7.557988</td>\n",
       "      <td>-3.988328</td>\n",
       "      <td>3.135895</td>\n",
       "      <td>2.052321</td>\n",
       "      <td>0.086258</td>\n",
       "      <td>8.273231</td>\n",
       "      <td>-4.989459</td>\n",
       "      <td>-2.281170</td>\n",
       "      <td>2.874825</td>\n",
       "      <td>2.547815</td>\n",
       "      <td>-0.141972</td>\n",
       "      <td>1.439112</td>\n",
       "      <td>1.932318</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-13.891866</td>\n",
       "      <td>13.612374</td>\n",
       "      <td>-10.400625</td>\n",
       "      <td>4.098095</td>\n",
       "      <td>8.260687</td>\n",
       "      <td>2.465724</td>\n",
       "      <td>-4.608547</td>\n",
       "      <td>-0.757423</td>\n",
       "      <td>-1.700104</td>\n",
       "      <td>4.058913</td>\n",
       "      <td>-1.559664</td>\n",
       "      <td>-0.296086</td>\n",
       "      <td>1.265823</td>\n",
       "      <td>-0.130142</td>\n",
       "      <td>1.531511</td>\n",
       "      <td>1.515075</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-17.539788</td>\n",
       "      <td>10.960154</td>\n",
       "      <td>-3.601321</td>\n",
       "      <td>-2.572278</td>\n",
       "      <td>11.733213</td>\n",
       "      <td>-0.222843</td>\n",
       "      <td>0.614663</td>\n",
       "      <td>3.460032</td>\n",
       "      <td>-4.524146</td>\n",
       "      <td>-0.049827</td>\n",
       "      <td>1.227205</td>\n",
       "      <td>2.752891</td>\n",
       "      <td>1.260994</td>\n",
       "      <td>0.553635</td>\n",
       "      <td>2.640660</td>\n",
       "      <td>1.285126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2         3          4         5         6  \\\n",
       "0  22.011624   2.197549  11.270368 -0.560723  -3.857200  4.611379 -5.389250   \n",
       "1 -20.554059  -4.985823   3.950644 -4.083574  11.507768  5.285352 -7.959067   \n",
       "2 -13.485705  -0.326685  -5.549856  7.557988  -3.988328  3.135895  2.052321   \n",
       "3 -13.891866  13.612374 -10.400625  4.098095   8.260687  2.465724 -4.608547   \n",
       "4 -17.539788  10.960154  -3.601321 -2.572278  11.733213 -0.222843  0.614663   \n",
       "\n",
       "          7         8         9        10        11        12        13  \\\n",
       "0 -0.374177  0.689210  0.140596  0.122384  1.126142  1.305294 -0.038265   \n",
       "1  4.183133 -4.442317 -4.939957  0.019306  5.375269  1.012978  0.344369   \n",
       "2  0.086258  8.273231 -4.989459 -2.281170  2.874825  2.547815 -0.141972   \n",
       "3 -0.757423 -1.700104  4.058913 -1.559664 -0.296086  1.265823 -0.130142   \n",
       "4  3.460032 -4.524146 -0.049827  1.227205  2.752891  1.260994  0.553635   \n",
       "\n",
       "         14        15  Hazard  \n",
       "0  1.539655 -1.044174       1  \n",
       "1  0.571722  1.589332       4  \n",
       "2  1.439112  1.932318       1  \n",
       "3  1.531511  1.515075       1  \n",
       "4  2.640660  1.285126       1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pca.iloc[:,0:16].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done  50 jobs       | elapsed:   20.2s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   40.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=100, n_jobs=1, oob_score=True, random_state=None,\n",
       "           verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "pca_train,pca_val=train_test_split(train_pca,test_size=0.33)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "alg=RandomForestRegressor(n_estimators=100, max_features = 'sqrt', oob_score=True, verbose = 1)\n",
    "alg.fit(pca_train.iloc[:,0:16],pca_train['Hazard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 jobs       | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.0s finished\n"
     ]
    }
   ],
   "source": [
    "predictions=alg.predict(pca_val.iloc[:,0:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2576399915221948"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gini(pca_val['Hazard'],predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 jobs       | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    2.7s finished\n"
     ]
    }
   ],
   "source": [
    "test_pca=pd.DataFrame(pca.transform(test[predictors]))\n",
    "predictions=alg.predict(test_pca)\n",
    "submission = pd.DataFrame({\n",
    "        \"Id\": test.index,\n",
    "        \"Hazard\": predictions\n",
    "    })\n",
    "\n",
    "submission.to_csv(\"submission_pca_rf.csv\", index=False, columns=['Id','Hazard'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
