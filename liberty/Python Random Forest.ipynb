{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train=pd.read_csv('train.csv')\n",
    "from sklearn import preprocessing\n",
    "#transform characters into numbers\n",
    "le=preprocessing.LabelEncoder()\n",
    "for i in range(train.shape[1]):\n",
    "    if train.iloc[:,i].dtype=='O':\n",
    "        train.iloc[:,i]=le.fit_transform(train.iloc[:,i])\n",
    "\n",
    "test=pd.read_csv('test.csv')\n",
    "for i in range(test.shape[1]):\n",
    "    if test.iloc[:,i].dtype=='O':\n",
    "        test.iloc[:,i]=le.fit_transform(test.iloc[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split the train set into train and validation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "train_train,train_val=train_test_split(train,test_size=0.33)\n",
    "predictors=train.columns.values.tolist()[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  50 jobs       | elapsed:    5.6s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   11.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=100, n_jobs=1, oob_score=True, random_state=None,\n",
       "           verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "alg=RandomForestRegressor(n_estimators=100, max_features = 'sqrt', oob_score=True, verbose = 1)\n",
    "alg.fit(train_train[predictors],train_train['Hazard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 jobs       | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "#predict on validation_set\n",
    "predictions=alg.predict(train_val[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simple implementation of the (normalized) gini score in numpy\n",
    "# Fully vectorized, no python loops, zips, etc.\n",
    "# Significantly (>30x) faster than previous implementions\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "def Gini(y_true, y_pred):\n",
    "    # check and get number of samples\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    n_samples = y_true.shape[0]\n",
    "    \n",
    "    # sort true values on prediction column \n",
    "    # (from largest to smallest)\n",
    "    arr = np.array([y_true, y_pred]).transpose()\n",
    "    true_order = arr[arr[:,0].argsort()][::-1,0]\n",
    "    pred_order = arr[arr[:,1].argsort()][::-1,0]\n",
    "    \n",
    "    # get Lorenz curves\n",
    "    L_true = np.cumsum(true_order) / np.sum(true_order)\n",
    "    L_pred = np.cumsum(pred_order) / np.sum(pred_order)\n",
    "    L_ones = np.linspace(1/n_samples, 1, n_samples)\n",
    "    \n",
    "    # get Gini coefficients (area between curves)\n",
    "    G_true = np.sum(L_ones - L_true)\n",
    "    G_pred = np.sum(L_ones - L_pred)\n",
    "    \n",
    "    # normalize to true Gini coefficient\n",
    "    return G_pred/G_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3197467298055684"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What do we have?\n",
    "Gini(train_val['Hazard'],predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done  50 jobs       | elapsed:   26.9s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   53.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now let's play with our forests\n",
    "alg=RandomForestRegressor(n_estimators=100, verbose = 1)\n",
    "alg.fit(train_train[predictors],train_train['Hazard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 jobs       | elapsed:    0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.314703469702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "predictions=alg.predict(train_val[predictors])\n",
    "print(Gini(train_val['Hazard'],predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.6s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    5.3s finished\n",
      "/home/egor/anaconda3/lib/python3.4/site-packages/sklearn/ensemble/forest.py:659: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.226218304942\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "alg=RandomForestRegressor(n_estimators=10, oob_score=True, verbose = 1)\n",
    "alg.fit(train_train[predictors],train_train['Hazard'])\n",
    "predictions=alg.predict(train_val[predictors]).round()\n",
    "print(Gini(train_val['Hazard'],predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done  50 jobs       | elapsed:  1.2min\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Phew, cool\n",
    "#Now let's try to train on the whole train data and make a prediction on test\n",
    "alg.fit(train[predictors],train['Hazard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  50 jobs       | elapsed:    1.7s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    3.5s finished\n"
     ]
    }
   ],
   "source": [
    "predictions=alg.predict(test[predictors])\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"Id\": test[\"Id\"],\n",
    "        \"Hazard\": predictions\n",
    "    })\n",
    "\n",
    "submission.to_csv(\"submission_python_rf.csv\", index=False, columns=['Id','Hazard'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.339149, less than I had with random forest from R.\n",
    "\n",
    "What if we try to fit classifier instead of regressor? After all, there's a lot of ones in the data and not much of other hazard levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  50 jobs       | elapsed:   11.3s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   35.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=True, random_state=None, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "alg=RandomForestClassifier(n_estimators=100, max_features = 'sqrt', oob_score=True, verbose = 1)\n",
    "alg.fit(train_train[predictors],train_train['Hazard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 jobs       | elapsed:    4.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 4]\n",
      "35096    1\n",
      "38644    1\n",
      "39823    1\n",
      "50014    4\n",
      "47841    1\n",
      "30753    1\n",
      "6301     8\n",
      "36897    1\n",
      "33004    4\n",
      "19042    2\n",
      "Name: Hazard, dtype: int64\n",
      "0.237323963156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   13.6s finished\n"
     ]
    }
   ],
   "source": [
    "predictions=alg.predict(train_val[predictors])\n",
    "print(predictions[:10])\n",
    "print(train_val['Hazard'][:10])\n",
    "print(Gini(train_val['Hazard'],predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done  50 jobs       | elapsed:   51.8s\n",
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed:  2.5min finished\n",
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 jobs       | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed:    4.5s finished\n"
     ]
    }
   ],
   "source": [
    "#stupid try with just ten trees and rounding of results\n",
    "alg=RandomForestRegressor(n_estimators=150, oob_score=True, verbose = 1)\n",
    "alg.fit(train[predictors],train['Hazard'])\n",
    "predictions=alg.predict(test[predictors]).round()\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"Id\": test[\"Id\"],\n",
    "        \"Hazard\": predictions\n",
    "    })\n",
    "\n",
    "submission.to_csv(\"submission_python_rf.csv\", index=False, columns=['Id','Hazard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.enable()\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
